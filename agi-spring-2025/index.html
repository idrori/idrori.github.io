<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C4D2T7XF9V"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-C4D2T7XF9V');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Artificial General Intelligence | Spring 2025 | BU</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            max-width: 800px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #fff;
        }

        h1 {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 0.25em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }

        h2 {
            font-size: 1.5em;
            font-weight: 600;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }

        h3 {
            font-size: 1.25em;
            font-weight: 600;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .subtitle {
            color: #586069;
            font-size: 1.1em;
            margin-bottom: 1.5em;
        }

        .info {
            margin-bottom: 0.5em;
        }

        .info strong {
            display: inline-block;
            min-width: 120px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 1em;
        }

        th, td {
            text-align: left;
            padding: 10px 12px;
            border-bottom: 1px solid #eaecef;
            vertical-align: top;
        }

        th {
            font-weight: 600;
            background: #f6f8fa;
        }

        tr:hover {
            background: #f6f8fa;
        }

        td.links {
            font-size: 0.9em;
        }

        footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            color: #586069;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <h1>Artificial General Intelligence</h1>
    <p class="subtitle">Graduate Course | Spring 2025 | Boston University</p>

    <h2>Course Information</h2>
    <p class="info"><strong>Instructor:</strong> Prof. Iddo Drori, CDS 839</p>
    <p class="info"><strong>Time:</strong> Monday and Wednesday, 5:00-6:15pm</p>
    <p class="info"><strong>Location:</strong> CDS 801</p>
    <p class="info"><strong>Prerequisites:</strong> ML or Deep Learning or AI or Computer Vision or NLP</p>
    <p class="info"><strong>Grading:</strong> Presentations 50%, Competition 40%, Participation 10%</p>

    <h2>Schedule</h2>
    <table>
        <thead>
            <tr>
                <th>Lecture</th>
                <th>Date</th>
                <th>Topic</th>
                <th>Reading</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td>Monday, January 20</td>
                <td>Martin Luther King Jr. Day (Holiday)</td>
                <td></td>
            </tr>
            <tr>
                <td>1</td>
                <td>Wednesday, January 22</td>
                <td>Reasoning Foundation Models</td>
                <td class="links">
                    <a href="https://arxiv.org/pdf/2201.11903">Chain-of-thought prompting elicits reasoning in large language models, Wei et al, 2022</a><br>
                    <a href="https://arxiv.org/pdf/2403.09629">Quiet-STaR: Language models can teach themselves to think before speaking, Zelikman et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2410.08146">Rewarding progress: Scaling automated process verifiers for LLM reasoning, Setlur et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2412.16339">Deliberative alignment: Reasoning enables safer language models, Guan et al, 2025</a><br>
                    <a href="https://arxiv.org/pdf/2501.04682">Towards system 2 reasoning in LLMs: Learning how to think with meta-chain-of-thought, Xiang et al, 2025</a><br>
                    <a href="https://github.com/YeTianJHU/AlphaLLM">AlphaLLM</a>: <a href="https://arxiv.org/pdf/2404.12253">Toward self-improvement of LLMs via imagination, searching, and criticizing, Tian et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2501.04519">rStar-Math: Small LLMs can master Math reasoning with self-evolved deep thinking, Guan et al, 2025</a><br>
                    <a href="https://arxiv.org/pdf/2412.01981">Free process rewards without process labels, Yuan et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2402.03300">DeepSeekMath: Pushing the limits of mathematical reasoning in open language models, Shao et al, 2024</a><br>
                    <a href="https://huggingface.co/blog/ganqu/prime">Process reinforcement through implicit rewards, Cui et al, 2025</a><br>
                    <a href="https://www.youtube.com/watch?v=SKBG1sqdyIU&t=1005s">OpenAI o3, Chen, Ren, Altman, 2024</a><br>
                    <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf">DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning, DeepSeek-AI, 2025</a>
                </td>
            </tr>
            <tr>
                <td>2</td>
                <td>Monday, January 27</td>
                <td>Self-Improving Foundation Models</td>
                <td class="links">
                    <a href="https://openreview.net/attachment?id=rFYeBznwop&name=pdf">Self-improving foundation models without human supervision, Setlur et al, 2024, see References</a>
                </td>
            </tr>
            <tr>
                <td>3</td>
                <td>Wednesday, January 29</td>
                <td>Open Source and Open Weights Foundation Models</td>
                <td class="links">
                    <a href="https://arxiv.org/pdf/2501.00656">2 OLMo 2 Furious, Walsh et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2412.19437">DeepSeek-V3 technical report, DeepSeek-AI, 2024</a><br>
                    <a href="https://novasky-ai.github.io/posts/sky-t1">Sky-T1, NovaSky, 2025</a><br>
                    <a href="https://arxiv.org/pdf/2409.02060">OLMoE: Open Mixture-of-Experts Language Models</a>
                </td>
            </tr>
            <tr>
                <td>4</td>
                <td>Monday, February 3</td>
                <td>World and Self Models</td>
                <td class="links">
                    <a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model">Genie 2: A large-scale foundation world model, Parker-Holder et al, 2024</a>
                </td>
            </tr>
            <tr>
                <td>5</td>
                <td>Wednesday, February 5</td>
                <td>AI Agents</td>
                <td class="links">
                    <a href="https://www.anthropic.com/research/building-effective-agents">Building effective agents, Anthropic, 2024</a><br>
                    Open source tools for building AI agents:<br>
                    <a href="https://www.anthropic.com/news/model-context-protocol">Model context protocol (MCP), Anthropic, 2024</a><br>
                    <a href="https://rivet.ironcladapp.com/">Rivet: Visual workflows</a><br>
                    <a href="https://www.langchain.com/langgraph">LangGraph: Graph workflows</a><br>
                    <a href="https://www.crewai.com/">CrewAI: Multi-agent systems</a><br>
                    <a href="https://github.com/openai/swarm">OpenAI Swarm: Multi-agent orchestration</a><br>
                    <a href="https://www.arxiv.org/pdf/2412.20138">Trading agents: Multi-agents LLM financial trading framework, Xiao et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2411.10109">Generative agent simulations of 1,000 people, Park et al, 2024</a>
                </td>
            </tr>
            <tr>
                <td>6</td>
                <td>Monday, February 10</td>
                <td>Generation, Synthetic Data, and Verification</td>
                <td class="links">
                    <a href="https://arxiv.org/pdf/2501.05707">Multiagent finetuning: Self improvement with diverse reasoning chains, Subramaniam et al, 2025</a>
                </td>
            </tr>
            <tr>
                <td>7</td>
                <td>Wednesday, February 12</td>
                <td>Invited Talk: Auto-Continual Learning, Prof. Joaquin Vanschoren</td>
                <td class="links"></td>
            </tr>
            <tr>
                <td></td>
                <td>Monday, February 17</td>
                <td>President's Day (No classes)</td>
                <td></td>
            </tr>
            <tr>
                <td>7</td>
                <td>Tuesday, February 18</td>
                <td>Weight-Space Learning</td>
                <td class="links"></td>
            </tr>
            <tr>
                <td>8</td>
                <td>Monday, February 24</td>
                <td>Small, Adaptive, Fast Learning, Self-Training Foundation Models</td>
                <td class="links">
                    <a href="https://arxiv.org/pdf/2409.05816">Improving pretraining data using perplexity correlations, Thrush et al, 2025</a><br>
                    LLM monorepo loss
                </td>
            </tr>
            <tr>
                <td>9</td>
                <td>Wednesday, February 26</td>
                <td>AI for Super-Human Mathematics</td>
                <td class="links">
                    IMO, autoformalization, Lean, test-time reinforcement learning<br>
                    <a href="https://goedel-lm.github.io/">Goedel-Prover: A frontier model for open-source automated theorem proving, Lin et al, 2025</a><br>
                    <a href="https://github.com/kfdong/STP">STP: Self-play LLM Theorem provers with iterative conjecturing and proving, Dong and Ma, 2025</a><br>
                    <a href="https://arxiv.org/pdf/2502.03544">Gold-medalist performance in solving Olympiad Geometry with AlphaGeometry2, Chervonyi et al, 2025</a>
                </td>
            </tr>
            <tr>
                <td>10</td>
                <td>Monday, March 3</td>
                <td>AI for Super-Human Visual Reasoning</td>
                <td class="links">
                    ARC, meta-learning, synthetic data, program synthesis, test-time training, human video screen analysis
                </td>
            </tr>
            <tr>
                <td>11</td>
                <td>Wednesday, March 5</td>
                <td>AI for Scientific Discovery</td>
                <td class="links">
                    <a href="https://arxiv.org/pdf/2409.04109">Can LLMs generate novel research ideas?, Si et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2408.06292">The AI scientist: Toward fully automated open-ended scientific discovery, Lu et al, 2024</a><br>
                    <a href="https://github.com/Future-House/paper-qa">PaperQA2</a>: <a href="https://arxiv.org/pdf/2409.13740">Language agents achieve superhuman synthesis of scientific knowledge, Skarlinski et al, 2024</a><br>
                    <a href="https://github.com/AutoSurveys/AutoSurvey">AutoSurvey</a>: <a href="https://arxiv.org/pdf/2406.10252">Large language models can automatically write surveys, Wang et al, 2024</a><br>
                    <a href="https://blog.iclr.cc/2024/10/09/iclr2025-assisting-reviewers">Review feedback agent: Assisting ICLR 2025 reviewers with feedback, Thakkar et al, 2024</a><br>
                    <a href="https://www.biorxiv.org/content/10.1101/2024.11.11.623004v1.full.pdf">The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation, Swanson et al, 2024</a>
                </td>
            </tr>
            <tr>
                <td></td>
                <td>Saturday, March 8 - Sunday, March 16</td>
                <td>Spring Recess</td>
                <td></td>
            </tr>
            <tr>
                <td>12</td>
                <td>Monday, March 17</td>
                <td>Video and Audio Analysis and Synthesis, Simulation</td>
                <td class="links"></td>
            </tr>
            <tr>
                <td>13</td>
                <td>Wednesday, March 19</td>
                <td>Meta Learning, AI Coding AI</td>
                <td class="links"></td>
            </tr>
            <tr>
                <td>14</td>
                <td>Monday, March 24</td>
                <td>Humanoid Robots</td>
                <td class="links">
                    <a href="https://drive.google.com/file/d/1UJ2yMrHnMR04xJ8kAecsWd9dhGicFahb/view?usp=sharing">Robots that learn, Malik, 2024</a><br>
                    <a href="https://developer.nvidia.com/isaac/gr00t">Isaac GR00T, Nvidia, 2024</a>
                </td>
            </tr>
            <tr>
                <td>15</td>
                <td>Wednesday, March 26</td>
                <td>Fly Brain</td>
                <td class="links">
                    <a href="https://www.nature.com/articles/s41586-024-07558-y">Neuronal wiring diagram of an adult brain, Dorkenwald et al, 2024</a><br>
                    <a href="https://www.nature.com/articles/s41586-024-07982-0">The fly connectome reveals a path to the effectome, Pospisil et al, 2024</a><br>
                    <a href="https://www.nature.com/articles/s41586-024-07953-5">Predicting visual function by interpreting a neuronal wiring diagram, Seung, 2024</a>
                </td>
            </tr>
            <tr>
                <td>16</td>
                <td>Monday, March 31</td>
                <td>Human Brain</td>
                <td class="links">
                    Human brain development, forebrain, midbrain, hindbrain, spinal cord.<br>
                    Cerebral cortex: frontal lobe, prefrontal cortex, parietal lobe, temporal lobe, Broca's area, auditory cortex, occipital lobe, Wernicke's area.<br>
                    Brain cells: Neuron, dendrite, microglia, oligodendrocyte, astrocyte, axon, synapse.<br>
                    Blood-brain barrier: Astrocyte, transporter, endothelial cell, pericyte.<br>
                    Pituitary gland: Hypothalamus, pituitary stalk, posterior lobe, capillaries, anterior lobe, thyroid.<br>
                    Surrounding layers: Arachnoid mater, dura mater, blood vessels in subarachnoid space, pia mater, connective tissue, white and gray matter.<br>
                    Self-cleaning: Cerebrospinal fluid, astrocyte, waste removal.<br>
                    Neurotransmitters: Adrenaline, noradrenaline, dopamine, oxytocin, GABA, acetylcholine, glutamate, endorphins, serotonin.<br>
                    Emotions: Anterior and posterior cingulate cortex, parahippocampal gyrus, hypothalamus, hippocampus, amygdala, septal nuclei.<br>
                    Placebo: Cingulate cortex, insula, thalamus, nucleus accumbens, amygdala, ventral tegmental area, periaqueductal gray matter.<br>
                    Memory: Frontal lobe, putamen, amygdala, temporal lobe, hippocampus, cerebellum, parietal lobe, caudate nucleus, thalamus.<br>
                    Memory types: Sensory, short-term, long-term procedural, declarative, episodic.<br>
                    Eyes: Optic nerve, optic chiasma, optic tract, thalamus, membrane, occipital lobes.<br>
                    Music: Parietal lobe, frontal lobe, superior temporal gyrus, planum temporale, auditory cortex, limbic circuit, insula.<br>
                    Timing: Cerebellum, basal ganglia.<br>
                    Consciousness<br>
                    Ethics<br><br>
                    <a href="https://arxiv.org/pdf/2408.10234">The unbearable slowness of being: Why do we live at 10 bits/s?, Zheng and Meister, 2024</a><br>
                    <a href="https://www.nature.com/articles/s43588-024-00731-3">Simulation and assimilation of the digital human brain, Lu et al, 2024</a>
                </td>
            </tr>
            <tr>
                <td>17</td>
                <td>Wednesday, April 2</td>
                <td>Human-AI Co-Evolution</td>
                <td class="links"></td>
            </tr>
            <tr>
                <td>18</td>
                <td>Monday, April 7</td>
                <td>Self-Improving AI Researcher</td>
                <td class="links">
                    <a href="https://openreview.net/pdf?id=rShJCyLsOr">A self-improving coding agent, Robeyns et al, 2025</a><br>
                    <a href="https://arxiv.org/pdf/2504.01848">PaperBench: Evaluating AI's ability to replicate AI research, Starace et al, 2025</a><br>
                    <a href="https://github.com/SakanaAI/AI-Scientist-v2">AI scientist v2, Yamada et al, 2025</a>
                </td>
            </tr>
            <tr>
                <td>19</td>
                <td>Wednesday, April 9</td>
                <td>AI for Simulating the Creation of Life on Earth</td>
                <td class="links">
                    <a href="https://www.science.org/doi/10.1126/sciadv.adt8979">Spraying of water microdroplets forms luminescence and causes chemical reactions in surrounding gas, Meng et al, 2025</a>
                </td>
            </tr>
            <tr>
                <td>20</td>
                <td>Monday, April 14</td>
                <td></td>
                <td class="links"></td>
            </tr>
            <tr>
                <td>21</td>
                <td>Wednesday, April 16</td>
                <td></td>
                <td class="links"></td>
            </tr>
            <tr>
                <td>22</td>
                <td>Wednesday, April 23</td>
                <td>AI for Reproducing JWST Findings of Alien Life</td>
                <td class="links">
                    <a href="https://iopscience.iop.org/article/10.3847/2041-8213/adc1c8/pdf">New constraints on DMS and DMDS in the atmosphere of K2-18 b from JWST MIRI, Madhusudhan et al, 2025</a><br>
                    <a href="https://mast.stsci.edu/search/ui/#/jwst/results?resolve=true&target=K2-18&radius=3&radius_units=arcseconds&useStore=false&search_key=9e1fd649c8e1">Data release 4/26/2025</a>
                </td>
            </tr>
            <tr>
                <td>23</td>
                <td>Monday, April 28</td>
                <td>Safety and Security</td>
                <td class="links">
                    <a href="https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf">AI Index report, Stanford, 2025</a><br>
                    <a href="https://ai-2027.com/">AI 2027 site</a>, <a href="https://ai-2027.com/ai-2027.pdf">manuscript</a><br>
                    <a href="https://assets.anthropic.com/m/24a47b00f10301cd/original/Anthropic-Responsible-Scaling-Policy-2024-10-15.pdf">Responsible scaling policy, Anthropic, 2024</a><br>
                    <a href="https://cdn.openai.com/spec/model-spec-2024-05-08.html">OpenAI model spec, 2024</a><br>
                    <a href="https://transluce.org/neuron-descriptions">Scaling automatic neuron description, Choi et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2504.05259">How to evaluate control measures for LLM agents? A trajectory from today to superintelligence, Korbak et al, 2025</a><br>
                    <a href="https://sleepinyourhat.github.io/checklist">What succeeding at AI safety will involve, Sam Bowman, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2504.01849">An approach to technical AGI safety and security, Shah et al, 2025</a>
                </td>
            </tr>
            <tr>
                <td>24</td>
                <td>Wednesday, April 30</td>
                <td>AI Governance</td>
                <td class="links">
                    <a href="https://www.rand.org/content/dam/rand/pubs/working_papers/WRA3000/WRA3056-1/RAND_WRA3056-1.pdf">Hardware-enabled governance mechanisms, Kulp et al, 2024</a><br>
                    <a href="https://arxiv.org/pdf/2407.14981">Open problems in technical AI governance, Reuel et al, 2024</a>
                </td>
            </tr>
        </tbody>
    </table>

    <footer>
        <p>&copy; 2025 Iddo Drori</p>
    </footer>
</body>
</html>
